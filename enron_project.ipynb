{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Fraud from Enron Email Project\n",
    "## June 2017, by Jude Moon\n",
    "<br />\n",
    "\n",
    "# Project Overview\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "In this project, I will play a detective, and put the new skills to use by building a person of interest (POI) identifier based on financial and email data made public as a result of the Enron scandal. I used [the provided dataset](link) from [Udacity Intro to Machine Learning Course](https://www.udacity.com/course/intro-to-machine-learning--ud120), which was combined with a hand-generated list of POI in the fraud case. POIs are individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity.\n",
    "\n",
    "This document is to keep notes as I work through the project and compose answers to [a series of questions](https://docs.google.com/document/d/1NDgi1PrNJP7WTbfSUuRUnz8yzs5nGVTSzpO7oeNTEWA/pub?embedded=true) provided by Udacity, to show my thought processes and approaches to solve this problem.\n",
    "***\n",
    "\n",
    "# Data Exploration\n",
    "## Q1-1: Summarize the goal of this project\n",
    "The goal of the Enron project is to build a valid algorithm to identify Enron Employees who may have committed fraud (labeled as a person of interest, aka POI), using features from their financial and email datasets.\n",
    "\n",
    "## Q1-2: Give some background on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pprint\n",
    "import operator\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loads up the dataset (pickled dict of dicts)\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Enron dataset (emails + finances) has the form:\n",
    "    \n",
    "    data_dict[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "    \n",
    "The data dictionary is stored as a **pickle** file, which is a handy way to store and load python objects directly.\n",
    "\n",
    "### How many data points (people) are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many POI?\n",
    "In other words, count the number of entries in the dictionary where\n",
    "data[person_name][\"poi\"]==1 \n",
    "- 1 means POI \n",
    "- 0 means non-POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POIs : 18\n",
      "Number of non-POIs : 128\n"
     ]
    }
   ],
   "source": [
    "count_poi = 0\n",
    "for person in data_dict:\n",
    "    if data_dict[person][\"poi\"] == 1:\n",
    "        count_poi += 1\n",
    "print \"Number of POIs : %i\" %count_poi\n",
    "print \"Number of non-POIs : %i\" %(146-count_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have sufficient data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st line: http://usatoday30.usatoday.com/money/industries/energy/2005-12-28-enron-participants_x.htm\n",
      "2nd line: \n",
      "3rd line: (y) Lay, Kenneth\n",
      "37th line: (n) Loehr, Christopher\n",
      "Number of POIs from Enron corpus: 35\n"
     ]
    }
   ],
   "source": [
    "# Udacity course provided a compiled list of all POI names from Enron corpus\n",
    "# poi_names.txt is newline delimited\n",
    "# read poi_names.txt file: each newline to string in a list\n",
    "poi_names_txt = open(\"poi_names.txt\", \"r\").read().splitlines()\n",
    "\n",
    "print \"1st line: \" + poi_names_txt[0]\n",
    "print \"2nd line: \" + poi_names_txt[1]\n",
    "print \"3rd line: \" + poi_names_txt[2]\n",
    "print \"37th line: \" + poi_names_txt[36]\n",
    "print \"Number of POIs from Enron corpus: %i\"%(len(poi_names_txt)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name list of POIs which were extracted from Enron corpus database (emails of total 158 employees) showed 35 of POIs, whereas the combined dataset of financial and email data had 18 of POIs. \n",
    "\n",
    "About half of POIs were missing in the email + finance data dictionary. This might cause problems on understanding the full scope of patterns between features and POI. \n",
    "\n",
    "However, adding POIs data points from email data to financial data and leaving \"NaN\" value for all financial features of missing POIs would introduce \"NaN\" driving biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each person, how many features are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[data_dict.keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salary',\n",
      " 'to_messages',\n",
      " 'deferral_payments',\n",
      " 'total_payments',\n",
      " 'exercised_stock_options',\n",
      " 'bonus',\n",
      " 'restricted_stock',\n",
      " 'shared_receipt_with_poi',\n",
      " 'restricted_stock_deferred',\n",
      " 'total_stock_value',\n",
      " 'expenses',\n",
      " 'loan_advances',\n",
      " 'from_messages',\n",
      " 'other',\n",
      " 'from_this_person_to_poi',\n",
      " 'poi',\n",
      " 'director_fees',\n",
      " 'deferred_income',\n",
      " 'long_term_incentive',\n",
      " 'email_address',\n",
      " 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "# the key of features for the first key\n",
    "features_list = data_dict[data_dict.keys()[0]].keys() \n",
    "pprint.pprint(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many NaN (Not a Number) exist per feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poi', 0),\n",
      " ('total_stock_value', 20),\n",
      " ('total_payments', 21),\n",
      " ('email_address', 35),\n",
      " ('restricted_stock', 36),\n",
      " ('exercised_stock_options', 44),\n",
      " ('salary', 51),\n",
      " ('expenses', 51),\n",
      " ('other', 53),\n",
      " ('to_messages', 60),\n",
      " ('shared_receipt_with_poi', 60),\n",
      " ('from_messages', 60),\n",
      " ('from_poi_to_this_person', 60),\n",
      " ('from_this_person_to_poi', 60),\n",
      " ('bonus', 64),\n",
      " ('long_term_incentive', 80),\n",
      " ('deferred_income', 97),\n",
      " ('deferral_payments', 107),\n",
      " ('restricted_stock_deferred', 128),\n",
      " ('director_fees', 129),\n",
      " ('loan_advances', 142)]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of feature and count of NaN pairs\n",
    "count_NaN = {}\n",
    "for feature in features_list:\n",
    "    count_NaN[feature] = 0\n",
    "\n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            count_NaN[feature] +=1\n",
    "\n",
    "# sort the dictionary by ascending ordering of values \n",
    "count_NaN = sorted(count_NaN.items(), key=operator.itemgetter(1))\n",
    "pprint.pprint(count_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would NaN introduce bias to the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4jude\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:25: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN_poi</th>\n",
       "      <th>NaN_total</th>\n",
       "      <th>NaN_non-poi</th>\n",
       "      <th>%NaN_in_poi</th>\n",
       "      <th>%NaN_in_non-poi</th>\n",
       "      <th>diff_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>-41.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.84375</td>\n",
       "      <td>-39.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>48.43750</td>\n",
       "      <td>-37.326389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>39.06250</td>\n",
       "      <td>-33.506944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>-31.423611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.34375</td>\n",
       "      <td>-27.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>57.81250</td>\n",
       "      <td>-24.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>27.34375</td>\n",
       "      <td>-21.788194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.40625</td>\n",
       "      <td>-16.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.62500</td>\n",
       "      <td>-15.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>125</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>97.65625</td>\n",
       "      <td>-3.211806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>94</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>73.43750</td>\n",
       "      <td>-1.215278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.68750</td>\n",
       "      <td>3.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>18</td>\n",
       "      <td>129</td>\n",
       "      <td>111</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>86.71875</td>\n",
       "      <td>13.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.93750</td>\n",
       "      <td>14.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NaN_poi  NaN_total  NaN_non-poi  %NaN_in_poi  \\\n",
       "other                            0         53           53     0.000000   \n",
       "expenses                         0         51           51     0.000000   \n",
       "bonus                            2         64           62    11.111111   \n",
       "salary                           1         51           50     5.555556   \n",
       "deferred_income                  7         97           90    38.888889   \n",
       "email_address                    0         35           35     0.000000   \n",
       "long_term_incentive              6         80           74    33.333333   \n",
       "restricted_stock                 1         36           35     5.555556   \n",
       "to_messages                      4         60           56    22.222222   \n",
       "shared_receipt_with_poi          4         60           56    22.222222   \n",
       "from_messages                    4         60           56    22.222222   \n",
       "from_poi_to_this_person          4         60           56    22.222222   \n",
       "from_this_person_to_poi          4         60           56    22.222222   \n",
       "total_payments                   0         21           21     0.000000   \n",
       "total_stock_value                0         20           20     0.000000   \n",
       "loan_advances                   17        142          125    94.444444   \n",
       "deferral_payments               13        107           94    72.222222   \n",
       "poi                              0          0            0     0.000000   \n",
       "exercised_stock_options          6         44           38    33.333333   \n",
       "director_fees                   18        129          111   100.000000   \n",
       "restricted_stock_deferred       18        128          110   100.000000   \n",
       "\n",
       "                           %NaN_in_non-poi     diff_%  \n",
       "other                             41.40625 -41.406250  \n",
       "expenses                          39.84375 -39.843750  \n",
       "bonus                             48.43750 -37.326389  \n",
       "salary                            39.06250 -33.506944  \n",
       "deferred_income                   70.31250 -31.423611  \n",
       "email_address                     27.34375 -27.343750  \n",
       "long_term_incentive               57.81250 -24.479167  \n",
       "restricted_stock                  27.34375 -21.788194  \n",
       "to_messages                       43.75000 -21.527778  \n",
       "shared_receipt_with_poi           43.75000 -21.527778  \n",
       "from_messages                     43.75000 -21.527778  \n",
       "from_poi_to_this_person           43.75000 -21.527778  \n",
       "from_this_person_to_poi           43.75000 -21.527778  \n",
       "total_payments                    16.40625 -16.406250  \n",
       "total_stock_value                 15.62500 -15.625000  \n",
       "loan_advances                     97.65625  -3.211806  \n",
       "deferral_payments                 73.43750  -1.215278  \n",
       "poi                                0.00000   0.000000  \n",
       "exercised_stock_options           29.68750   3.645833  \n",
       "director_fees                     86.71875  13.281250  \n",
       "restricted_stock_deferred         85.93750  14.062500  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary showing the number of NaN and \n",
    "# number of POI with NaN each feature\n",
    "NaN_dict = {}\n",
    "keys = ['NaN_total', 'NaN_poi']\n",
    "\n",
    "for key in keys:\n",
    "    NaN_dict[key] = {}\n",
    "    for feature in features_list:\n",
    "        NaN_dict[key][feature] = 0\n",
    "        \n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            NaN_dict['NaN_total'][feature] +=1\n",
    "        \n",
    "        if data_dict[person][feature] == \"NaN\" and data_dict[person]['poi'] == True:\n",
    "            NaN_dict['NaN_poi'][feature] +=1\n",
    "\n",
    "# convert from a dictionary to a panda dataframe\n",
    "NaN_df = pd.DataFrame(NaN_dict)\n",
    "NaN_df['NaN_non-poi'] = NaN_df['NaN_total']-NaN_df['NaN_poi']\n",
    "NaN_df['%NaN_in_poi'] = (NaN_df['NaN_poi']/18)*100 # from total 18 POI\n",
    "NaN_df['%NaN_in_non-poi'] = (NaN_df['NaN_non-poi']/128)*100 # from total 128 non-POI\n",
    "NaN_df['diff_%'] = NaN_df['%NaN_in_poi'] - NaN_df['%NaN_in_non-poi']\n",
    "NaN_df = NaN_df.sort(['diff_%'])\n",
    "NaN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought that features with a greater number of \"NaN\" value (e.g. 'loan_advances', 'director_fees', 'restricted_stock_deferred', etc.) would introduce bias. However, the disproportion in the numbers of \"NaN\" value between POI labeled group vs. non-POI labeled group might be more problematic. The features with large differences between % NaN in POI group vs. % NaN in non-POI group, for example, 'other' and 'expenses' are likely biased by \"NaN\" value. This means that if a supervised classification algorithm was to use 'other' as a feature, I would think that it might interpret \"NaN\" for 'other' as a clue that a person is a non-POI, so I would expect it to associate a \"NaN\" value with non-POI label.\n",
    "\n",
    "I am not sure whether it is ok to associate lack of information such as \"NaN\" value with a particular label. I will keep this in mind and consider excluding the NaN biased features at the feature selection stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of data exploration\n",
    "- Total number of data points: 146\n",
    "- Total number of data points labeled as POI: 18\n",
    "- Total number of data points labeled as non-POI: 126\n",
    "- Number of missing POIs: 17\n",
    "- Number of initial features: 21\n",
    "- List of features with the number of \"NaN\" value greater than 73 (50% cut-off): \n",
    "\n",
    "| feature name  | number of NaN  |\n",
    "|:---:|:---:|\n",
    "| 'loan_advances' | 142  |\n",
    "| 'director_fees'  | 129  |\n",
    "| 'restricted_stock_deferred'  | 128  |\n",
    "|  'deferral_payments' | 107  |\n",
    "| 'deferred_income'  | 97  |\n",
    "| 'long_term_incentive'  |  80 |\n",
    "    \n",
    "\n",
    "- List of features with \"NaN\" value disproportionally distributed between POI vs. non-POI groups:\n",
    "\n",
    "|    feature_name   | NaN_total | NaN_poi | NaN_non-poi | %NaN_in_poi | %NaN_in_non-poi | %Difference|\n",
    "|:-----------------:|:---------:|:-------:|:-----------:|:-----------:|:---------------:|:---------------:|\n",
    "|      'other'      |     53    |    0    |      53     |      0      |        41       |       -41       |\n",
    "|     'expenses'    |     51    |    0    |      51     |      0      |        40       |       -40       |\n",
    "|      'bonus'      |     64    |    2    |      62     |      11     |        48       |       -37       |\n",
    "|      'salary'     |     51    |    1    |      50     |      6      |        39       |       -34       |\n",
    "| 'deferred_income' |     97    |    7    |      90     |      39     |        70       |       -31       |\n",
    "\n",
    "## Q1-3: How machine learning is useful in trying to accomplish the project goal and answer the project question\n",
    "\n",
    "It is uncertain that the existing financial and email dataset can provide good indicators/predictors to identify POI. After data exploration, I realized that there are some limitations such as NaN driving bias and missing half of POIs. \n",
    "\n",
    "With these limitations and imperfect situation, machine learning can be useful in discovering some hidden patterns in features associated with POI labels and understanding relationship between a feature or a bundle of features and POI labels. After validating and evaluating the performance of machine learning algorithm, we can answer whether the features in the dataset can indicate or predict identification of POI. \n",
    "\n",
    "According to scikit-learn algorithm cheat-sheet below, predicting a category>yes>do you have labeled data>yes>less than 100k samples>yes> and the options are:\n",
    "\n",
    "\n",
    "- Linear SVC \n",
    "- KNeighbors Classifier \n",
    "- SVC ensemble classifiers   \n",
    "\n",
    "![image](http://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Investigation\n",
    "\n",
    "### Who has the most NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WHALEY DAVID A', 18),\n",
      " ('WROBEL BRUCE', 18),\n",
      " ('THE TRAVEL AGENCY IN THE PARK', 18),\n",
      " ('GRAMM WENDY L', 18),\n",
      " ('LOCKHART EUGENE E', 20)]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of person and count of NaN pairs\n",
    "missing_value = {}\n",
    "\n",
    "for person in data_dict:\n",
    "    missing_value[person] = 0\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            missing_value[person] +=1\n",
    "\n",
    "# sort the dictionary by ascending ordering of values \n",
    "missing_value = sorted(missing_value.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# print top 5 those who have the most NaN\n",
    "pprint.pprint(missing_value[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance at numerical variable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to summary statistics of each feature, I use pandas dataframe\n",
    "# convert a python dictionary to a dataframe \n",
    "# with features as columns and people as rows\n",
    "df = pd.DataFrame(data_dict)\n",
    "df_trans = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.333474e+06</td>\n",
       "      <td>4.387965e+05</td>\n",
       "      <td>-3.827622e+05</td>\n",
       "      <td>1.942249e+04</td>\n",
       "      <td>4.182736e+06</td>\n",
       "      <td>7.074827e+04</td>\n",
       "      <td>358.602740</td>\n",
       "      <td>38.226027</td>\n",
       "      <td>24.287671</td>\n",
       "      <td>1.149658e+06</td>\n",
       "      <td>6.646839e+05</td>\n",
       "      <td>5.854318e+05</td>\n",
       "      <td>1.749257e+06</td>\n",
       "      <td>2.051637e+04</td>\n",
       "      <td>3.658114e+05</td>\n",
       "      <td>692.986301</td>\n",
       "      <td>1221.589041</td>\n",
       "      <td>4.350622e+06</td>\n",
       "      <td>5.846018e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.094029e+06</td>\n",
       "      <td>2.741325e+06</td>\n",
       "      <td>2.378250e+06</td>\n",
       "      <td>1.190543e+05</td>\n",
       "      <td>2.607040e+07</td>\n",
       "      <td>4.327163e+05</td>\n",
       "      <td>1441.259868</td>\n",
       "      <td>73.901124</td>\n",
       "      <td>79.278206</td>\n",
       "      <td>9.649342e+06</td>\n",
       "      <td>4.046072e+06</td>\n",
       "      <td>3.682345e+06</td>\n",
       "      <td>1.089995e+07</td>\n",
       "      <td>1.439661e+06</td>\n",
       "      <td>2.203575e+06</td>\n",
       "      <td>1072.969492</td>\n",
       "      <td>2226.770637</td>\n",
       "      <td>2.693448e+07</td>\n",
       "      <td>3.624681e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.792600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.115000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.394475e+04</td>\n",
       "      <td>2.288695e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>2.018200e+04</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>3.605280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.105960e+05</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>9.413595e+05</td>\n",
       "      <td>9.659550e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>9.684500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.714221e+06</td>\n",
       "      <td>5.374075e+04</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.750648e+05</td>\n",
       "      <td>1.506065e+05</td>\n",
       "      <td>8.145280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.708505e+05</td>\n",
       "      <td>893.500000</td>\n",
       "      <td>1585.750000</td>\n",
       "      <td>1.968287e+06</td>\n",
       "      <td>2.319991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>4.345095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  1.460000e+02       1.460000e+02     1.460000e+02   1.460000e+02   \n",
       "mean   1.333474e+06       4.387965e+05    -3.827622e+05   1.942249e+04   \n",
       "std    8.094029e+06       2.741325e+06     2.378250e+06   1.190543e+05   \n",
       "min    0.000000e+00      -1.025000e+05    -2.799289e+07   0.000000e+00   \n",
       "25%    0.000000e+00       0.000000e+00    -3.792600e+04   0.000000e+00   \n",
       "50%    3.000000e+05       0.000000e+00     0.000000e+00   0.000000e+00   \n",
       "75%    8.000000e+05       9.684500e+03     0.000000e+00   0.000000e+00   \n",
       "max    9.734362e+07       3.208340e+07     0.000000e+00   1.398517e+06   \n",
       "\n",
       "       exercised_stock_options      expenses  from_messages  \\\n",
       "count             1.460000e+02  1.460000e+02     146.000000   \n",
       "mean              4.182736e+06  7.074827e+04     358.602740   \n",
       "std               2.607040e+07  4.327163e+05    1441.259868   \n",
       "min               0.000000e+00  0.000000e+00       0.000000   \n",
       "25%               0.000000e+00  0.000000e+00       0.000000   \n",
       "50%               6.082935e+05  2.018200e+04      16.500000   \n",
       "75%               1.714221e+06  5.374075e+04      51.250000   \n",
       "max               3.117640e+08  5.235198e+06   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "count               146.000000               146.000000   1.460000e+02   \n",
       "mean                 38.226027                24.287671   1.149658e+06   \n",
       "std                  73.901124                79.278206   9.649342e+06   \n",
       "min                   0.000000                 0.000000   0.000000e+00   \n",
       "25%                   0.000000                 0.000000   0.000000e+00   \n",
       "50%                   2.500000                 0.000000   0.000000e+00   \n",
       "75%                  40.750000                13.750000   0.000000e+00   \n",
       "max                 528.000000               609.000000   8.392500e+07   \n",
       "\n",
       "       long_term_incentive         other  restricted_stock  \\\n",
       "count         1.460000e+02  1.460000e+02      1.460000e+02   \n",
       "mean          6.646839e+05  5.854318e+05      1.749257e+06   \n",
       "std           4.046072e+06  3.682345e+06      1.089995e+07   \n",
       "min           0.000000e+00  0.000000e+00     -2.604490e+06   \n",
       "25%           0.000000e+00  0.000000e+00      8.115000e+03   \n",
       "50%           0.000000e+00  9.595000e+02      3.605280e+05   \n",
       "75%           3.750648e+05  1.506065e+05      8.145280e+05   \n",
       "max           4.852193e+07  4.266759e+07      1.303223e+08   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.460000e+02  1.460000e+02               146.000000   \n",
       "mean                2.051637e+04  3.658114e+05               692.986301   \n",
       "std                 1.439661e+06  2.203575e+06              1072.969492   \n",
       "min                -7.576788e+06  0.000000e+00                 0.000000   \n",
       "25%                 0.000000e+00  0.000000e+00                 0.000000   \n",
       "50%                 0.000000e+00  2.105960e+05               102.500000   \n",
       "75%                 0.000000e+00  2.708505e+05               893.500000   \n",
       "max                 1.545629e+07  2.670423e+07              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count    146.000000    1.460000e+02       1.460000e+02  \n",
       "mean    1221.589041    4.350622e+06       5.846018e+06  \n",
       "std     2226.770637    2.693448e+07       3.624681e+07  \n",
       "min        0.000000    0.000000e+00      -4.409300e+04  \n",
       "25%        0.000000    9.394475e+04       2.288695e+05  \n",
       "50%      289.000000    9.413595e+05       9.659550e+05  \n",
       "75%     1585.750000    1.968287e+06       2.319991e+06  \n",
       "max    15149.000000    3.098866e+08       4.345095e+08  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get numerical statistics, replace \"NaN\" to zero (0)\n",
    "def to_zero(v):\n",
    "    if v == 'NaN':\n",
    "        v = 0\n",
    "    return v\n",
    "df_trans = df_trans.applymap(to_zero)\n",
    "df_trans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-4: Are there any outliers in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': ['LAVORATO JOHN J', 'TOTAL'],\n",
      " 'deferral_payments': ['FREVERT MARK A', 'TOTAL'],\n",
      " 'deferred_income': [],\n",
      " 'director_fees': ['BHATNAGAR SANJAY', 'TOTAL'],\n",
      " 'exercised_stock_options': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'expenses': ['MCCLELLAN GEORGE', 'TOTAL'],\n",
      " 'from_messages': ['KAMINSKI WINCENTY J', 'KEAN STEVEN J'],\n",
      " 'from_poi_to_this_person': ['DIETRICH JANET R', 'LAVORATO JOHN J'],\n",
      " 'from_this_person_to_poi': ['DELAINEY DAVID W', 'LAVORATO JOHN J'],\n",
      " 'loan_advances': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'long_term_incentive': ['MARTIN AMANDA K', 'TOTAL'],\n",
      " 'other': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'restricted_stock': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'restricted_stock_deferred': ['BELFER ROBERT', 'BHATNAGAR SANJAY'],\n",
      " 'salary': ['SKILLING JEFFREY K', 'TOTAL'],\n",
      " 'shared_receipt_with_poi': ['BELDEN TIMOTHY N', 'SHAPIRO RICHARD S'],\n",
      " 'to_messages': ['KEAN STEVEN J', 'SHAPIRO RICHARD S'],\n",
      " 'total_payments': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'total_stock_value': ['LAY KENNETH L', 'TOTAL']}\n"
     ]
    }
   ],
   "source": [
    "# I defined outliers as being above of 99% quantile here\n",
    "# get lists of people above 99% quantile for each feature\n",
    "highest = {}\n",
    "for column in df_trans.columns:\n",
    "    if df_trans[column].dtypes == \"int64\":\n",
    "        highest[column]=[]\n",
    "        q = df_trans[column].quantile(0.99)\n",
    "        highest[column] = df_trans[data_df[column] > q].index.tolist()\n",
    "    \n",
    "pprint.pprint(highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the outliers repeatedly shown among the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DELAINEY DAVID W', 1),\n",
       " ('MARTIN AMANDA K', 1),\n",
       " ('SKILLING JEFFREY K', 1),\n",
       " ('BELDEN TIMOTHY N', 1),\n",
       " ('DIETRICH JANET R', 1),\n",
       " ('FREVERT MARK A', 1),\n",
       " ('KAMINSKI WINCENTY J', 1),\n",
       " ('BELFER ROBERT', 1),\n",
       " ('MCCLELLAN GEORGE', 1),\n",
       " ('KEAN STEVEN J', 2),\n",
       " ('BHATNAGAR SANJAY', 2),\n",
       " ('SHAPIRO RICHARD S', 2),\n",
       " ('LAVORATO JOHN J', 3),\n",
       " ('LAY KENNETH L', 6),\n",
       " ('TOTAL', 12)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the previous dictionary, highest\n",
    "# create a dictionary of outliers and the frequency of being outlier\n",
    "highest_count = {}\n",
    "for feature in highest:\n",
    "    for person in highest[feature]:\n",
    "        if person not in highest_count:\n",
    "            highest_count[person] = 1\n",
    "        else:\n",
    "            highest_count[person] += 1\n",
    "            \n",
    "highest_count = sorted(highest_count.items(), key=operator.itemgetter(1))   \n",
    "highest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of outlier Investigation\n",
    "\n",
    "- Top 5 people who has the most \"NaN\":\n",
    "\n",
    "|          person name          | number of NaN |\n",
    "|:-----------------------------:|:-------------:|\n",
    "|       LOCKHART EUGENE E       |       20      |\n",
    "|         GRAMM WENDY L         |       18      |\n",
    "| THE TRAVEL AGENCY IN THE PARK |       18      |\n",
    "|          WROBEL BRUCE         |       18      |\n",
    "|         WHALEY DAVID A        |       18      |\n",
    "\n",
    "- Top 3 people repeatedly shown as outliers:\n",
    "\n",
    "|   person name   | frequency of being outlier |\n",
    "|:---------------:|:--------------------------:|\n",
    "|      TOTAL      |             12             |\n",
    "|  LAY KENNETH L  |              6             |\n",
    "| LAVORATO JOHN J |              3             |\n",
    "\n",
    "### Take a look at outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97343619</td>\n",
       "      <td>7000000</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32083396</td>\n",
       "      <td>202911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27992891</td>\n",
       "      <td>-300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1398517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kenneth.lay@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130</td>\n",
       "      <td>98718</td>\n",
       "      <td>311764000</td>\n",
       "      <td>34348384</td>\n",
       "      <td>4158995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5235198</td>\n",
       "      <td>99832</td>\n",
       "      <td>49537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83925000</td>\n",
       "      <td>81525000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48521928</td>\n",
       "      <td>3600000</td>\n",
       "      <td>2035380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42667589</td>\n",
       "      <td>10359729</td>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130322299</td>\n",
       "      <td>14761694</td>\n",
       "      <td>1008149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7576788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26704229</td>\n",
       "      <td>1072321</td>\n",
       "      <td>339288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2411</td>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4273</td>\n",
       "      <td>7259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>362096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309886585</td>\n",
       "      <td>103559793</td>\n",
       "      <td>10425757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130</td>\n",
       "      <td>98718</td>\n",
       "      <td>434509511</td>\n",
       "      <td>49110078</td>\n",
       "      <td>5167144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          LOCKHART EUGENE E GRAMM WENDY L  \\\n",
       "bonus                                   NaN           NaN   \n",
       "deferral_payments                       NaN           NaN   \n",
       "deferred_income                         NaN           NaN   \n",
       "director_fees                           NaN        119292   \n",
       "email_address                           NaN           NaN   \n",
       "exercised_stock_options                 NaN           NaN   \n",
       "expenses                                NaN           NaN   \n",
       "from_messages                           NaN           NaN   \n",
       "from_poi_to_this_person                 NaN           NaN   \n",
       "from_this_person_to_poi                 NaN           NaN   \n",
       "loan_advances                           NaN           NaN   \n",
       "long_term_incentive                     NaN           NaN   \n",
       "other                                   NaN           NaN   \n",
       "poi                                   False         False   \n",
       "restricted_stock                        NaN           NaN   \n",
       "restricted_stock_deferred               NaN           NaN   \n",
       "salary                                  NaN           NaN   \n",
       "shared_receipt_with_poi                 NaN           NaN   \n",
       "to_messages                             NaN           NaN   \n",
       "total_payments                          NaN        119292   \n",
       "total_stock_value                       NaN           NaN   \n",
       "\n",
       "                          THE TRAVEL AGENCY IN THE PARK WROBEL BRUCE  \\\n",
       "bonus                                               NaN          NaN   \n",
       "deferral_payments                                   NaN          NaN   \n",
       "deferred_income                                     NaN          NaN   \n",
       "director_fees                                       NaN          NaN   \n",
       "email_address                                       NaN          NaN   \n",
       "exercised_stock_options                             NaN       139130   \n",
       "expenses                                            NaN          NaN   \n",
       "from_messages                                       NaN          NaN   \n",
       "from_poi_to_this_person                             NaN          NaN   \n",
       "from_this_person_to_poi                             NaN          NaN   \n",
       "loan_advances                                       NaN          NaN   \n",
       "long_term_incentive                                 NaN          NaN   \n",
       "other                                            362096          NaN   \n",
       "poi                                               False        False   \n",
       "restricted_stock                                    NaN          NaN   \n",
       "restricted_stock_deferred                           NaN          NaN   \n",
       "salary                                              NaN          NaN   \n",
       "shared_receipt_with_poi                             NaN          NaN   \n",
       "to_messages                                         NaN          NaN   \n",
       "total_payments                                   362096          NaN   \n",
       "total_stock_value                                   NaN       139130   \n",
       "\n",
       "                          WHALEY DAVID A      TOTAL          LAY KENNETH L  \\\n",
       "bonus                                NaN   97343619                7000000   \n",
       "deferral_payments                    NaN   32083396                 202911   \n",
       "deferred_income                      NaN  -27992891                -300000   \n",
       "director_fees                        NaN    1398517                    NaN   \n",
       "email_address                        NaN        NaN  kenneth.lay@enron.com   \n",
       "exercised_stock_options            98718  311764000               34348384   \n",
       "expenses                             NaN    5235198                  99832   \n",
       "from_messages                        NaN        NaN                     36   \n",
       "from_poi_to_this_person              NaN        NaN                    123   \n",
       "from_this_person_to_poi              NaN        NaN                     16   \n",
       "loan_advances                        NaN   83925000               81525000   \n",
       "long_term_incentive                  NaN   48521928                3600000   \n",
       "other                                NaN   42667589               10359729   \n",
       "poi                                False      False                   True   \n",
       "restricted_stock                     NaN  130322299               14761694   \n",
       "restricted_stock_deferred            NaN   -7576788                    NaN   \n",
       "salary                               NaN   26704229                1072321   \n",
       "shared_receipt_with_poi              NaN        NaN                   2411   \n",
       "to_messages                          NaN        NaN                   4273   \n",
       "total_payments                       NaN  309886585              103559793   \n",
       "total_stock_value                  98718  434509511               49110078   \n",
       "\n",
       "                                   LAVORATO JOHN J  \n",
       "bonus                                      8000000  \n",
       "deferral_payments                              NaN  \n",
       "deferred_income                                NaN  \n",
       "director_fees                                  NaN  \n",
       "email_address              john.lavorato@enron.com  \n",
       "exercised_stock_options                    4158995  \n",
       "expenses                                     49537  \n",
       "from_messages                                 2585  \n",
       "from_poi_to_this_person                        528  \n",
       "from_this_person_to_poi                        411  \n",
       "loan_advances                                  NaN  \n",
       "long_term_incentive                        2035380  \n",
       "other                                         1552  \n",
       "poi                                          False  \n",
       "restricted_stock                           1008149  \n",
       "restricted_stock_deferred                      NaN  \n",
       "salary                                      339288  \n",
       "shared_receipt_with_poi                       3962  \n",
       "to_messages                                   7259  \n",
       "total_payments                            10425757  \n",
       "total_stock_value                          5167144  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['LOCKHART EUGENE E', 'GRAMM WENDY L', \\\n",
    "    'THE TRAVEL AGENCY IN THE PARK', \\\n",
    "    'WROBEL BRUCE', 'WHALEY DAVID A', \\\n",
    "    'TOTAL', 'LAY KENNETH L', 'LAVORATO JOHN J']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-5: How to handle outliers?\n",
    "\n",
    "'TOTAL' seemed an outlier introduced by spreadsheet quirk. It was the sum of all entries from the [pdf financial data](enron61702insiderpay.pdf). It needs to be removed from the dataset.\n",
    "\n",
    "In addition, 'LOCKHART EUGENE E' might need to be removed as well because he does not have any value other than NaN and is labeled as non-POI. \n",
    "\n",
    "Among the outliers and data points with too many missing values, only 'LAY KENNETH L' was labeled as POI and he was chairman of the Enron board of directors. So I think these extreme values for this individual have a meaningful reason, not introduced by typos or technical errors.\n",
    "\n",
    "'LAVORATO JOHN J' is an interesting individual who was recieved the largest bonus and the most frequently communicated with POI via emails, but he is not labeled as POI. So, I expect that this person would be lied near the border line of classification or tend to be mis-classified.\n",
    "\n",
    "I tend to keep the other outliers detected, including 'THE TRAVEL AGENCY IN THE PARK'. According to the footnote from the [pdf financial data](enron61702insiderpay.pdf), the travel agency was coowned by the sister of Enron's former Chairman and I don't have solid reasons to exclude this from the dataset.\n",
    "\n",
    "- List of data points to remove:\n",
    "    \n",
    "    - 'TOTAL'\n",
    "    - 'LOCKHART EUGENE E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### there's an outlier--remove it! \n",
    "data_dict.pop(\"TOTAL\", 0)\n",
    "data_dict.pop(\"LOCKHART EUGENE E\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Create new features\n",
    "\n",
    " As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) \n",
    "\n",
    "calculate \"fraction_to_this_person_from_poi\" and \"fraction_from_this_person_to_poi\", using \"from_poi_to_this_person\", \"from_poi_to_this_person\", \"from_messages\", and \"to_messages\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python dictionary can’t be read directly into an sklearn classification or regression algorithm; instead, it needs a numpy array or a list of lists (each element of the list (itself a list) is a data point, and the elements of the smaller list are the features of that point).\n",
    "\n",
    "Udacity has written helper functions (featureFormat() and targetFeatureSplit() in feature_format.py) that can take a list of feature names and the data dictionary, and return a numpy array.\n",
    "\n",
    "In the case when a feature does not have a value for a particular person, this function will also replace the feature value with 0 (zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "   \"\"\"\n",
    "\n",
    "    ### beware of \"NaN\" when there is no known email address (and so\n",
    "    ### no filled email features), and integer division!\n",
    "    ### in case of poi_messages or all_messages having \"NaN\" value, return 0.\n",
    "    fraction = 0.\n",
    "    if all_messages == 'NaN':\n",
    "        return fraction\n",
    "    \n",
    "    if poi_messages == 'NaN':\n",
    "        poi_messages = 0\n",
    "    \n",
    "    fraction = float(poi_messages)/float(all_messages)\n",
    "\n",
    "    return fraction\n",
    "\n",
    "\n",
    "newfeature_dict = {}\n",
    "for name in data_dict:\n",
    "    \n",
    "    data_point = data_dict[name]\n",
    "    \n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction(from_poi_to_this_person, to_messages)\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi\n",
    "    \n",
    "    newfeature_dict[name]={\"fraction_from_poi\":fraction_from_poi,\n",
    "                       \"fraction_to_poi\":fraction_to_poi}\n",
    "    data_dict[name][\"fraction_from_poi\"] = fraction_from_poi\n",
    "    data_dict[name][\"fraction_to_poi\"] = fraction_to_poi\n",
    "    \n",
    "\n",
    "print newfeature_dict['METTS MARK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data_dict['METTS MARK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_dict['METTS MARK'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have total 23 key-value pairs per name. Before adding two, we had 21 total key-value pairs per name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finacial_feature_list = ['salary', 'deferral_payments', 'total_payments', \n",
    "                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "               'deferred_income', 'total_stock_value', 'expenses',\n",
    "               'exercised_stock_options', 'other', 'long_term_incentive',\n",
    "               'restricted_stock', 'director_fees'] \n",
    "\n",
    "# numeric feataure list which excludes email adress\n",
    "email_feature_list = ['to_messages', 'from_poi_to_this_person', 'from_messages',\n",
    "                     'from_this_person_to_poi', 'shared_receipt_with_poi', \n",
    "                      \"fraction_from_poi\", \"fraction_to_poi\"]\n",
    "label = ['poi']\n",
    "\n",
    "total_feature_list = label + finacial_feature_list + email_feature_list\n",
    "\n",
    "print total_feature_list\n",
    "print len(total_feature_list)\n",
    "print len(finacial_feature_list)\n",
    "print len(email_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total 23 key-value pairs per name minus 1 key-value pair(email_address). So now we have 14 finacial features, 7 email features, and 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all numeric features and convert dictionary to numpy array of features\n",
    "data_nparray = featureFormat(data_dict, total_feature_list)\n",
    "poi, total_features = targetFeatureSplit(data_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many data points (people) are in the dataset?\n",
    "# number of keys\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nparray[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of key was 146 - 1('TOTAL') - 1(all zeros) = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "rescaled_data_nparray = scaler.fit_transform(data_nparray)\n",
    "rescaled_data_nparray[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except zero of poi, zero value is not truely zero. Try to figure out how to scale features without zero values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call for salary\n",
    "data_nparray[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to figure out how to MinMaxScaler() excluding NaN \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "array = np.array([[115.], [140.], [175.], ['NaN']])\n",
    "new_array = []\n",
    "for value in array:\n",
    "    if value != 'NaN':\n",
    "        new_array.append(value)\n",
    "new_nparray = np.array(new_array)\n",
    "print new_array\n",
    "print new_nparray\n",
    "scaler = MinMaxScaler()\n",
    "rescaled_array = scaler.fit_transform(new_array)\n",
    "rescaled_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better option can be\n",
    "http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "imputation of missing values:\n",
    "The Imputer class provides basic strategies for imputing missing values, either using the mean, the median or the most frequent value of the row or column in which the missing values are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure out how to use imputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "a = [[1, 2], [np.nan, 3], [9, 6]]\n",
    "imp.fit(a)\n",
    "imp.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "c = [[1, 2], [np.nan, 3], [9, 6]]\n",
    "data_imp = imp.fit_transform(c)\n",
    "\n",
    "data_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert dictionary to numpy array of features with NaN\n",
    "data_nparray_wNaN = featureFormat(data_dict, total_feature_list, remove_NaN=False, remove_all_zeroes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_nparray_wNaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_nparray_wNaN[:, 1]\n",
    "data_nparray_wNaN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "data_nparray_wNaN_imp = imp.fit_transform(data_nparray_wNaN)\n",
    "data_nparray_wNaN_imp[0]                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why there are negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of deferral_payments\n",
    "min(data_nparray[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of deferrd_income\n",
    "min(data_nparray[:, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of total_stock_value\n",
    "min(data_nparray[:, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the financial data have negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "rescaled_data_nparray_imp = scaler.fit_transform(data_nparray_wNaN_imp)\n",
    "rescaled_data_nparray_imp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why median value is not around 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_mean = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data_nparray_wNaN_imp_mean = imp_mean.fit_transform(data_nparray_wNaN)\n",
    "print data_nparray_wNaN_imp_mean[0] \n",
    "print \n",
    "rescaled_data_nparray_imp_mean = scaler.fit_transform(data_nparray_wNaN_imp_mean)\n",
    "print rescaled_data_nparray_imp_mean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why mean value is not around 0.5. I think it is because the mean value calculated without the number of the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stand = StandardScaler()\n",
    "stand_data_nparray_imp = stand.fit_transform(data_nparray_wNaN_imp)\n",
    "stand_data_nparray_imp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert numpy array to list\n",
    "poi, total_rescaled_features = targetFeatureSplit(rescaled_data_nparray_imp)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 44)\n",
    "\n",
    "clf.fit(total_rescaled_features, poi)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Total Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{}: no.{}, {} ({})\".format(i+1,indices[i], \n",
    "                                      total_feature_list[indices[i]+1],\n",
    "                            importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_array = rescaled_data_nparray_imp[:, 0]\n",
    "rescaled_total_data_nparray_imp = rescaled_data_nparray_imp[:, 1:]\n",
    "rescaled_financial_data_nparray_imp = rescaled_data_nparray_imp[:, 1:15]\n",
    "rescaled_email_data_nparray_imp = rescaled_data_nparray_imp[:, 15:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# important financial features\n",
    "\n",
    "clf.fit(rescaled_financial_data_nparray_imp, poi_array)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Financial Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{}: no.{}, {} ({})\".format(i+1,indices[i],\n",
    "                                      finacial_feature_list[indices[i]], \n",
    "                                      importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# important email features\n",
    "\n",
    "clf.fit(rescaled_email_data_nparray_imp, poi_array)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Email Feature Ranking: '\n",
    "for i in range(5):\n",
    "    print \"{}: no.{}, {} ({})\".format(i+1,indices[i],\n",
    "                                      email_feature_list[indices[i]], \n",
    "                                      importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(rescaled_total_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_ # % of variance explained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# financial featrues\n",
    "pca.fit(rescaled_financial_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# email featrues\n",
    "pca.fit(rescaled_email_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
