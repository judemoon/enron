{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Fraud from Enron Email Project\n",
    "## June 2017, by Jude Moon\n",
    "<br />\n",
    "\n",
    "# Project Overview\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "In this project, I will play a detective, and put the new skills to use by building a person of interest (POI) identifier based on financial and email data made public as a result of the Enron scandal. I used [the provided dataset](link) from [Udacity Intro to Machine Learning Course](https://www.udacity.com/course/intro-to-machine-learning--ud120), which was combined with a hand-generated list of POI in the fraud case. POIs are individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity.\n",
    "\n",
    "This document is to keep notes as I work through the project and compose answers to [a series of questions](https://docs.google.com/document/d/1NDgi1PrNJP7WTbfSUuRUnz8yzs5nGVTSzpO7oeNTEWA/pub?embedded=true) provided by Udacity, to show my thought processes and approaches to solve this problem.\n",
    "***\n",
    "\n",
    "# Part1. Data Exploration\n",
    "## Q1-1: Summarize the goal of this project\n",
    "The goal of the Enron project is to build a valid algorithm to identify Enron Employees who may have committed fraud (labeled as a person of interest, aka POI), using features from their financial and email datasets.\n",
    "\n",
    "## Q1-2: Give some background on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pprint\n",
    "import operator\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loads up the dataset (pickled dict of dicts)\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Enron dataset (emails + finances) has the form:\n",
    "    \n",
    "    data_dict[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "    \n",
    "The data dictionary is stored as a **pickle** file, which is a handy way to store and load python objects directly.\n",
    "\n",
    "### How many data points (people) are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many POI?\n",
    "In other words, count the number of entries in the dictionary where\n",
    "data[person_name][\"poi\"]==1 \n",
    "- 1 means POI \n",
    "- 0 means non-POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POIs : 18\n",
      "Number of non-POIs : 128\n"
     ]
    }
   ],
   "source": [
    "count_poi = 0\n",
    "for person in data_dict:\n",
    "    if data_dict[person][\"poi\"] == 1:\n",
    "        count_poi += 1\n",
    "print \"Number of POIs : %i\" %count_poi\n",
    "print \"Number of non-POIs : %i\" %(146-count_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have sufficient data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st line: http://usatoday30.usatoday.com/money/industries/energy/2005-12-28-enron-participants_x.htm\n",
      "2nd line: \n",
      "3rd line: (y) Lay, Kenneth\n",
      "37th line: (n) Loehr, Christopher\n",
      "Number of POIs from Enron corpus: 35\n"
     ]
    }
   ],
   "source": [
    "# Udacity course provided a compiled list of all POI names from Enron corpus\n",
    "# poi_names.txt is newline delimited\n",
    "# read poi_names.txt file: each newline to string in a list\n",
    "poi_names_txt = open(\"poi_names.txt\", \"r\").read().splitlines()\n",
    "\n",
    "print \"1st line: \" + poi_names_txt[0]\n",
    "print \"2nd line: \" + poi_names_txt[1]\n",
    "print \"3rd line: \" + poi_names_txt[2]\n",
    "print \"37th line: \" + poi_names_txt[36]\n",
    "print \"Number of POIs from Enron corpus: %i\"%(len(poi_names_txt)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name list of POIs which were extracted from Enron corpus database (emails of total 158 employees) showed 35 of POIs, whereas the combined dataset of financial and email data had 18 of POIs. \n",
    "\n",
    "About half of POIs were missing in the email + finance data dictionary. This might cause problems on understanding the full scope of patterns between features and POI. \n",
    "\n",
    "However, adding POIs data points from email data to financial data and leaving \"NaN\" value for all financial features of missing POIs would introduce \"NaN\" driving biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each person, how many features are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[data_dict.keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salary',\n",
      " 'to_messages',\n",
      " 'deferral_payments',\n",
      " 'total_payments',\n",
      " 'exercised_stock_options',\n",
      " 'bonus',\n",
      " 'restricted_stock',\n",
      " 'shared_receipt_with_poi',\n",
      " 'restricted_stock_deferred',\n",
      " 'total_stock_value',\n",
      " 'expenses',\n",
      " 'loan_advances',\n",
      " 'from_messages',\n",
      " 'other',\n",
      " 'from_this_person_to_poi',\n",
      " 'poi',\n",
      " 'director_fees',\n",
      " 'deferred_income',\n",
      " 'long_term_incentive',\n",
      " 'email_address',\n",
      " 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "# the key of features for the first key\n",
    "features_list = data_dict[data_dict.keys()[0]].keys() \n",
    "pprint.pprint(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many NaN (Not a Number) exist per feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poi', 0),\n",
      " ('total_stock_value', 20),\n",
      " ('total_payments', 21),\n",
      " ('email_address', 35),\n",
      " ('restricted_stock', 36),\n",
      " ('exercised_stock_options', 44),\n",
      " ('salary', 51),\n",
      " ('expenses', 51),\n",
      " ('other', 53),\n",
      " ('to_messages', 60),\n",
      " ('shared_receipt_with_poi', 60),\n",
      " ('from_messages', 60),\n",
      " ('from_poi_to_this_person', 60),\n",
      " ('from_this_person_to_poi', 60),\n",
      " ('bonus', 64),\n",
      " ('long_term_incentive', 80),\n",
      " ('deferred_income', 97),\n",
      " ('deferral_payments', 107),\n",
      " ('restricted_stock_deferred', 128),\n",
      " ('director_fees', 129),\n",
      " ('loan_advances', 142)]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of feature and count of NaN pairs\n",
    "count_NaN = {}\n",
    "for feature in features_list:\n",
    "    count_NaN[feature] = 0\n",
    "\n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            count_NaN[feature] +=1\n",
    "\n",
    "# sort the dictionary by ascending ordering of values \n",
    "count_NaN = sorted(count_NaN.items(), key=operator.itemgetter(1))\n",
    "pprint.pprint(count_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would NaN introduce bias to the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4jude\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:25: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN_poi</th>\n",
       "      <th>NaN_total</th>\n",
       "      <th>NaN_non-poi</th>\n",
       "      <th>%NaN_in_poi</th>\n",
       "      <th>%NaN_in_non-poi</th>\n",
       "      <th>diff_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>-41.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.84375</td>\n",
       "      <td>-39.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>48.43750</td>\n",
       "      <td>-37.326389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>39.06250</td>\n",
       "      <td>-33.506944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>70.31250</td>\n",
       "      <td>-31.423611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.34375</td>\n",
       "      <td>-27.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>57.81250</td>\n",
       "      <td>-24.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>27.34375</td>\n",
       "      <td>-21.788194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>43.75000</td>\n",
       "      <td>-21.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.40625</td>\n",
       "      <td>-16.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.62500</td>\n",
       "      <td>-15.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>125</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>97.65625</td>\n",
       "      <td>-3.211806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>94</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>73.43750</td>\n",
       "      <td>-1.215278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>29.68750</td>\n",
       "      <td>3.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>18</td>\n",
       "      <td>129</td>\n",
       "      <td>111</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>86.71875</td>\n",
       "      <td>13.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.93750</td>\n",
       "      <td>14.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NaN_poi  NaN_total  NaN_non-poi  %NaN_in_poi  \\\n",
       "other                            0         53           53     0.000000   \n",
       "expenses                         0         51           51     0.000000   \n",
       "bonus                            2         64           62    11.111111   \n",
       "salary                           1         51           50     5.555556   \n",
       "deferred_income                  7         97           90    38.888889   \n",
       "email_address                    0         35           35     0.000000   \n",
       "long_term_incentive              6         80           74    33.333333   \n",
       "restricted_stock                 1         36           35     5.555556   \n",
       "to_messages                      4         60           56    22.222222   \n",
       "shared_receipt_with_poi          4         60           56    22.222222   \n",
       "from_messages                    4         60           56    22.222222   \n",
       "from_poi_to_this_person          4         60           56    22.222222   \n",
       "from_this_person_to_poi          4         60           56    22.222222   \n",
       "total_payments                   0         21           21     0.000000   \n",
       "total_stock_value                0         20           20     0.000000   \n",
       "loan_advances                   17        142          125    94.444444   \n",
       "deferral_payments               13        107           94    72.222222   \n",
       "poi                              0          0            0     0.000000   \n",
       "exercised_stock_options          6         44           38    33.333333   \n",
       "director_fees                   18        129          111   100.000000   \n",
       "restricted_stock_deferred       18        128          110   100.000000   \n",
       "\n",
       "                           %NaN_in_non-poi     diff_%  \n",
       "other                             41.40625 -41.406250  \n",
       "expenses                          39.84375 -39.843750  \n",
       "bonus                             48.43750 -37.326389  \n",
       "salary                            39.06250 -33.506944  \n",
       "deferred_income                   70.31250 -31.423611  \n",
       "email_address                     27.34375 -27.343750  \n",
       "long_term_incentive               57.81250 -24.479167  \n",
       "restricted_stock                  27.34375 -21.788194  \n",
       "to_messages                       43.75000 -21.527778  \n",
       "shared_receipt_with_poi           43.75000 -21.527778  \n",
       "from_messages                     43.75000 -21.527778  \n",
       "from_poi_to_this_person           43.75000 -21.527778  \n",
       "from_this_person_to_poi           43.75000 -21.527778  \n",
       "total_payments                    16.40625 -16.406250  \n",
       "total_stock_value                 15.62500 -15.625000  \n",
       "loan_advances                     97.65625  -3.211806  \n",
       "deferral_payments                 73.43750  -1.215278  \n",
       "poi                                0.00000   0.000000  \n",
       "exercised_stock_options           29.68750   3.645833  \n",
       "director_fees                     86.71875  13.281250  \n",
       "restricted_stock_deferred         85.93750  14.062500  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary showing the number of NaN and \n",
    "# number of POI with NaN each feature\n",
    "NaN_dict = {}\n",
    "keys = ['NaN_total', 'NaN_poi']\n",
    "\n",
    "for key in keys:\n",
    "    NaN_dict[key] = {}\n",
    "    for feature in features_list:\n",
    "        NaN_dict[key][feature] = 0\n",
    "        \n",
    "for person in data_dict:\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            NaN_dict['NaN_total'][feature] +=1\n",
    "        \n",
    "        if data_dict[person][feature] == \"NaN\" and data_dict[person]['poi'] == True:\n",
    "            NaN_dict['NaN_poi'][feature] +=1\n",
    "\n",
    "# convert from a dictionary to a panda dataframe\n",
    "NaN_df = pd.DataFrame(NaN_dict)\n",
    "NaN_df['NaN_non-poi'] = NaN_df['NaN_total']-NaN_df['NaN_poi']\n",
    "NaN_df['%NaN_in_poi'] = (NaN_df['NaN_poi']/18)*100 # from total 18 POI\n",
    "NaN_df['%NaN_in_non-poi'] = (NaN_df['NaN_non-poi']/128)*100 # from total 128 non-POI\n",
    "NaN_df['diff_%'] = NaN_df['%NaN_in_poi'] - NaN_df['%NaN_in_non-poi']\n",
    "NaN_df = NaN_df.sort(['diff_%'])\n",
    "NaN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought that features with a greater number of \"NaN\" value (e.g. 'loan_advances', 'director_fees', 'restricted_stock_deferred', etc.) would introduce bias. However, the disproportion in the numbers of \"NaN\" value between POI labeled group vs. non-POI labeled group might be more problematic. The features with large differences between % NaN in POI group vs. % NaN in non-POI group, for example, 'other' and 'expenses' are likely biased by \"NaN\" value. This means that if a supervised classification algorithm was to use 'other' as a feature, I would think that it might interpret \"NaN\" for 'other' as a clue that a person is a non-POI, so I would expect it to associate a \"NaN\" value with non-POI label.\n",
    "\n",
    "I am not sure whether it is ok to associate lack of information such as \"NaN\" value with a particular label. I will keep this in mind and consider excluding the NaN biased features at the feature selection stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of data exploration\n",
    "- Total number of data points: 146\n",
    "- Total number of data points labeled as POI: 18\n",
    "- Total number of data points labeled as non-POI: 126\n",
    "- Imbalanced classes\n",
    "- Number of missing POIs: 17\n",
    "- Number of initial features: 21\n",
    "- List of features with the number of \"NaN\" value greater than 73 (50% cut-off): \n",
    "\n",
    "| feature name  | number of NaN  |\n",
    "|:---:|:---:|\n",
    "| 'loan_advances' | 142  |\n",
    "| 'director_fees'  | 129  |\n",
    "| 'restricted_stock_deferred'  | 128  |\n",
    "|  'deferral_payments' | 107  |\n",
    "| 'deferred_income'  | 97  |\n",
    "| 'long_term_incentive'  |  80 |\n",
    "    \n",
    "\n",
    "- List of features with \"NaN\" value disproportionally distributed between POI vs. non-POI groups:\n",
    "\n",
    "|    feature_name   | NaN_total | NaN_poi | NaN_non-poi | %NaN_in_poi | %NaN_in_non-poi | %Difference|\n",
    "|:-----------------:|:---------:|:-------:|:-----------:|:-----------:|:---------------:|:---------------:|\n",
    "|      'other'      |     53    |    0    |      53     |      0      |        41       |       -41       |\n",
    "|     'expenses'    |     51    |    0    |      51     |      0      |        40       |       -40       |\n",
    "|      'bonus'      |     64    |    2    |      62     |      11     |        48       |       -37       |\n",
    "|      'salary'     |     51    |    1    |      50     |      6      |        39       |       -34       |\n",
    "| 'deferred_income' |     97    |    7    |      90     |      39     |        70       |       -31       |\n",
    "\n",
    "## Q1-3: How machine learning is useful in trying to accomplish the project goal and answer the project question\n",
    "\n",
    "It is uncertain that the existing financial and email dataset can provide good indicators/predictors in identifying POI. After data exploration, I realized that there are some limitations such as NaN driving bias and missing half of POIs. \n",
    "\n",
    "With these limitations and imperfect situation, machine learning can be useful in discovering some hidden patterns in features associated with POI labels and understanding relationship between a feature or a bundle of features and POI labels. After validating and evaluating the performance of machine learning algorithm, we can answer whether these simple numeric features can indicate or predict identification of POI. \n",
    "\n",
    "According to scikit-learn algorithm cheat-sheet below, predicting a category>yes>do you have labeled data>yes>less than 100k samples>yes> and the options are:\n",
    "\n",
    "\n",
    "- Linear SVC \n",
    "- KNeighbors Classifier \n",
    "- SVC ensemble classifiers   \n",
    "\n",
    "![image](http://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Investigation\n",
    "\n",
    "### Who has the most NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WHALEY DAVID A', 18),\n",
      " ('WROBEL BRUCE', 18),\n",
      " ('THE TRAVEL AGENCY IN THE PARK', 18),\n",
      " ('GRAMM WENDY L', 18),\n",
      " ('LOCKHART EUGENE E', 20)]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary of person and count of NaN pairs\n",
    "missing_value = {}\n",
    "\n",
    "for person in data_dict:\n",
    "    missing_value[person] = 0\n",
    "    for feature in data_dict[person]:\n",
    "        if data_dict[person][feature] == \"NaN\":\n",
    "            missing_value[person] +=1\n",
    "\n",
    "# sort the dictionary by ascending ordering of values \n",
    "missing_value = sorted(missing_value.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# print top 5 those who have the most NaN\n",
    "pprint.pprint(missing_value[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glance at numerical variable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to summary statistics of each feature, I use pandas dataframe\n",
    "# convert a python dictionary to a dataframe \n",
    "# with features as columns and people as rows\n",
    "df = pd.DataFrame(data_dict)\n",
    "df_trans = df.transpose()\n",
    "#df_trans = df_trans.replace('NaN', 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.759974e+05</td>\n",
       "      <td>2.220896e+05</td>\n",
       "      <td>-1.936833e+05</td>\n",
       "      <td>9980.319444</td>\n",
       "      <td>2.075802e+06</td>\n",
       "      <td>35375.340278</td>\n",
       "      <td>363.583333</td>\n",
       "      <td>38.756944</td>\n",
       "      <td>24.625000</td>\n",
       "      <td>5.828125e+05</td>\n",
       "      <td>3.369578e+05</td>\n",
       "      <td>2.972601e+05</td>\n",
       "      <td>8.685363e+05</td>\n",
       "      <td>7.341790e+04</td>\n",
       "      <td>1.854460e+05</td>\n",
       "      <td>702.611111</td>\n",
       "      <td>1238.555556</td>\n",
       "      <td>2.259057e+06</td>\n",
       "      <td>2.909786e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.233155e+06</td>\n",
       "      <td>7.541013e+05</td>\n",
       "      <td>6.060111e+05</td>\n",
       "      <td>31300.575144</td>\n",
       "      <td>4.795513e+06</td>\n",
       "      <td>45309.303038</td>\n",
       "      <td>1450.675239</td>\n",
       "      <td>74.276769</td>\n",
       "      <td>79.778266</td>\n",
       "      <td>6.794472e+06</td>\n",
       "      <td>6.871826e+05</td>\n",
       "      <td>1.131068e+06</td>\n",
       "      <td>2.016572e+06</td>\n",
       "      <td>1.301983e+06</td>\n",
       "      <td>1.970421e+05</td>\n",
       "      <td>1077.290736</td>\n",
       "      <td>2237.564816</td>\n",
       "      <td>8.846594e+06</td>\n",
       "      <td>6.189018e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-3.504386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-1.787380e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.708600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.434500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.964825e+04</td>\n",
       "      <td>2.443265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>20182.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>3.605280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.105960e+05</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>347.500000</td>\n",
       "      <td>9.413595e+05</td>\n",
       "      <td>9.659550e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>8.535500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.683580e+06</td>\n",
       "      <td>53328.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.745862e+05</td>\n",
       "      <td>1.505075e+05</td>\n",
       "      <td>7.374560e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.696675e+05</td>\n",
       "      <td>933.750000</td>\n",
       "      <td>1623.000000</td>\n",
       "      <td>1.945668e+06</td>\n",
       "      <td>2.295176e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>6.426990e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>137864.000000</td>\n",
       "      <td>3.434838e+07</td>\n",
       "      <td>228763.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>8.152500e+07</td>\n",
       "      <td>5.145434e+06</td>\n",
       "      <td>1.035973e+07</td>\n",
       "      <td>1.476169e+07</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>1.111258e+06</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>1.035598e+08</td>\n",
       "      <td>4.911008e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  1.440000e+02       1.440000e+02     1.440000e+02     144.000000   \n",
       "mean   6.759974e+05       2.220896e+05    -1.936833e+05    9980.319444   \n",
       "std    1.233155e+06       7.541013e+05     6.060111e+05   31300.575144   \n",
       "min    0.000000e+00      -1.025000e+05    -3.504386e+06       0.000000   \n",
       "25%    0.000000e+00       0.000000e+00    -3.708600e+04       0.000000   \n",
       "50%    3.000000e+05       0.000000e+00     0.000000e+00       0.000000   \n",
       "75%    8.000000e+05       8.535500e+03     0.000000e+00       0.000000   \n",
       "max    8.000000e+06       6.426990e+06     0.000000e+00  137864.000000   \n",
       "\n",
       "       exercised_stock_options       expenses  from_messages  \\\n",
       "count             1.440000e+02     144.000000     144.000000   \n",
       "mean              2.075802e+06   35375.340278     363.583333   \n",
       "std               4.795513e+06   45309.303038    1450.675239   \n",
       "min               0.000000e+00       0.000000       0.000000   \n",
       "25%               0.000000e+00       0.000000       0.000000   \n",
       "50%               6.082935e+05   20182.000000      17.500000   \n",
       "75%               1.683580e+06   53328.250000      53.000000   \n",
       "max               3.434838e+07  228763.000000   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "count               144.000000               144.000000   1.440000e+02   \n",
       "mean                 38.756944                24.625000   5.828125e+05   \n",
       "std                  74.276769                79.778266   6.794472e+06   \n",
       "min                   0.000000                 0.000000   0.000000e+00   \n",
       "25%                   0.000000                 0.000000   0.000000e+00   \n",
       "50%                   4.000000                 0.000000   0.000000e+00   \n",
       "75%                  41.250000                14.000000   0.000000e+00   \n",
       "max                 528.000000               609.000000   8.152500e+07   \n",
       "\n",
       "       long_term_incentive         other  restricted_stock  \\\n",
       "count         1.440000e+02  1.440000e+02      1.440000e+02   \n",
       "mean          3.369578e+05  2.972601e+05      8.685363e+05   \n",
       "std           6.871826e+05  1.131068e+06      2.016572e+06   \n",
       "min           0.000000e+00  0.000000e+00     -2.604490e+06   \n",
       "25%           0.000000e+00  0.000000e+00      2.434500e+04   \n",
       "50%           0.000000e+00  9.595000e+02      3.605280e+05   \n",
       "75%           3.745862e+05  1.505075e+05      7.374560e+05   \n",
       "max           5.145434e+06  1.035973e+07      1.476169e+07   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.440000e+02  1.440000e+02               144.000000   \n",
       "mean                7.341790e+04  1.854460e+05               702.611111   \n",
       "std                 1.301983e+06  1.970421e+05              1077.290736   \n",
       "min                -1.787380e+06  0.000000e+00                 0.000000   \n",
       "25%                 0.000000e+00  0.000000e+00                 0.000000   \n",
       "50%                 0.000000e+00  2.105960e+05               114.000000   \n",
       "75%                 0.000000e+00  2.696675e+05               933.750000   \n",
       "max                 1.545629e+07  1.111258e+06              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count    144.000000    1.440000e+02       1.440000e+02  \n",
       "mean    1238.555556    2.259057e+06       2.909786e+06  \n",
       "std     2237.564816    8.846594e+06       6.189018e+06  \n",
       "min        0.000000    0.000000e+00      -4.409300e+04  \n",
       "25%        0.000000    9.964825e+04       2.443265e+05  \n",
       "50%      347.500000    9.413595e+05       9.659550e+05  \n",
       "75%     1623.000000    1.945668e+06       2.295176e+06  \n",
       "max    15149.000000    1.035598e+08       4.911008e+07  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get numerical statistics, replace string \"NaN\" to zero (0)\n",
    "def to_zero(v):\n",
    "    if v == 'NaN':\n",
    "        v = 0\n",
    "    return v\n",
    "df_trans = df_trans.applymap(to_zero)\n",
    "df_trans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-4: Are there any outliers in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': ['LAVORATO JOHN J', 'TOTAL'],\n",
      " 'deferral_payments': ['FREVERT MARK A', 'TOTAL'],\n",
      " 'deferred_income': [],\n",
      " 'director_fees': ['BHATNAGAR SANJAY', 'TOTAL'],\n",
      " 'exercised_stock_options': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'expenses': ['MCCLELLAN GEORGE', 'TOTAL'],\n",
      " 'from_messages': ['KAMINSKI WINCENTY J', 'KEAN STEVEN J'],\n",
      " 'from_poi_to_this_person': ['DIETRICH JANET R', 'LAVORATO JOHN J'],\n",
      " 'from_this_person_to_poi': ['DELAINEY DAVID W', 'LAVORATO JOHN J'],\n",
      " 'loan_advances': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'long_term_incentive': ['MARTIN AMANDA K', 'TOTAL'],\n",
      " 'other': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'restricted_stock': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'restricted_stock_deferred': ['BELFER ROBERT', 'BHATNAGAR SANJAY'],\n",
      " 'salary': ['SKILLING JEFFREY K', 'TOTAL'],\n",
      " 'shared_receipt_with_poi': ['BELDEN TIMOTHY N', 'SHAPIRO RICHARD S'],\n",
      " 'to_messages': ['KEAN STEVEN J', 'SHAPIRO RICHARD S'],\n",
      " 'total_payments': ['LAY KENNETH L', 'TOTAL'],\n",
      " 'total_stock_value': ['LAY KENNETH L', 'TOTAL']}\n"
     ]
    }
   ],
   "source": [
    "# I defined outliers as being above of 99% quantile here\n",
    "# get lists of people above 99% quantile for each feature\n",
    "highest = {}\n",
    "for column in df_trans.columns:\n",
    "    if df_trans[column].dtypes == \"int64\":\n",
    "        highest[column]=[]\n",
    "        q = df_trans[column].quantile(0.99)\n",
    "        highest[column] = df_trans[data_df[column] > q].index.tolist()\n",
    "    \n",
    "pprint.pprint(highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the outliers repeatedly shown among the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DELAINEY DAVID W', 1),\n",
       " ('MARTIN AMANDA K', 1),\n",
       " ('SKILLING JEFFREY K', 1),\n",
       " ('BELDEN TIMOTHY N', 1),\n",
       " ('DIETRICH JANET R', 1),\n",
       " ('FREVERT MARK A', 1),\n",
       " ('KAMINSKI WINCENTY J', 1),\n",
       " ('BELFER ROBERT', 1),\n",
       " ('MCCLELLAN GEORGE', 1),\n",
       " ('KEAN STEVEN J', 2),\n",
       " ('BHATNAGAR SANJAY', 2),\n",
       " ('SHAPIRO RICHARD S', 2),\n",
       " ('LAVORATO JOHN J', 3),\n",
       " ('LAY KENNETH L', 6),\n",
       " ('TOTAL', 12)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the previous dictionary, highest\n",
    "# create a dictionary of outliers and the frequency of being outlier\n",
    "highest_count = {}\n",
    "for feature in highest:\n",
    "    for person in highest[feature]:\n",
    "        if person not in highest_count:\n",
    "            highest_count[person] = 1\n",
    "        else:\n",
    "            highest_count[person] += 1\n",
    "            \n",
    "highest_count = sorted(highest_count.items(), key=operator.itemgetter(1))   \n",
    "highest_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of outlier Investigation\n",
    "\n",
    "- Top 5 people who has the most \"NaN\":\n",
    "\n",
    "|          person name          | number of NaN |\n",
    "|:-----------------------------:|:-------------:|\n",
    "|       LOCKHART EUGENE E       |       20      |\n",
    "|         GRAMM WENDY L         |       18      |\n",
    "| THE TRAVEL AGENCY IN THE PARK |       18      |\n",
    "|          WROBEL BRUCE         |       18      |\n",
    "|         WHALEY DAVID A        |       18      |\n",
    "\n",
    "- Top 3 people repeatedly shown as outliers:\n",
    "\n",
    "|   person name   | frequency of being outlier |\n",
    "|:---------------:|:--------------------------:|\n",
    "|      TOTAL      |             12             |\n",
    "|  LAY KENNETH L  |              6             |\n",
    "| LAVORATO JOHN J |              3             |\n",
    "\n",
    "### Take a look at outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97343619</td>\n",
       "      <td>7000000</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32083396</td>\n",
       "      <td>202911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27992891</td>\n",
       "      <td>-300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1398517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kenneth.lay@enron.com</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130</td>\n",
       "      <td>98718</td>\n",
       "      <td>311764000</td>\n",
       "      <td>34348384</td>\n",
       "      <td>4158995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5235198</td>\n",
       "      <td>99832</td>\n",
       "      <td>49537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83925000</td>\n",
       "      <td>81525000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48521928</td>\n",
       "      <td>3600000</td>\n",
       "      <td>2035380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42667589</td>\n",
       "      <td>10359729</td>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130322299</td>\n",
       "      <td>14761694</td>\n",
       "      <td>1008149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7576788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26704229</td>\n",
       "      <td>1072321</td>\n",
       "      <td>339288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2411</td>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4273</td>\n",
       "      <td>7259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>362096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309886585</td>\n",
       "      <td>103559793</td>\n",
       "      <td>10425757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130</td>\n",
       "      <td>98718</td>\n",
       "      <td>434509511</td>\n",
       "      <td>49110078</td>\n",
       "      <td>5167144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          LOCKHART EUGENE E GRAMM WENDY L  \\\n",
       "bonus                                   NaN           NaN   \n",
       "deferral_payments                       NaN           NaN   \n",
       "deferred_income                         NaN           NaN   \n",
       "director_fees                           NaN        119292   \n",
       "email_address                           NaN           NaN   \n",
       "exercised_stock_options                 NaN           NaN   \n",
       "expenses                                NaN           NaN   \n",
       "from_messages                           NaN           NaN   \n",
       "from_poi_to_this_person                 NaN           NaN   \n",
       "from_this_person_to_poi                 NaN           NaN   \n",
       "loan_advances                           NaN           NaN   \n",
       "long_term_incentive                     NaN           NaN   \n",
       "other                                   NaN           NaN   \n",
       "poi                                   False         False   \n",
       "restricted_stock                        NaN           NaN   \n",
       "restricted_stock_deferred               NaN           NaN   \n",
       "salary                                  NaN           NaN   \n",
       "shared_receipt_with_poi                 NaN           NaN   \n",
       "to_messages                             NaN           NaN   \n",
       "total_payments                          NaN        119292   \n",
       "total_stock_value                       NaN           NaN   \n",
       "\n",
       "                          THE TRAVEL AGENCY IN THE PARK WROBEL BRUCE  \\\n",
       "bonus                                               NaN          NaN   \n",
       "deferral_payments                                   NaN          NaN   \n",
       "deferred_income                                     NaN          NaN   \n",
       "director_fees                                       NaN          NaN   \n",
       "email_address                                       NaN          NaN   \n",
       "exercised_stock_options                             NaN       139130   \n",
       "expenses                                            NaN          NaN   \n",
       "from_messages                                       NaN          NaN   \n",
       "from_poi_to_this_person                             NaN          NaN   \n",
       "from_this_person_to_poi                             NaN          NaN   \n",
       "loan_advances                                       NaN          NaN   \n",
       "long_term_incentive                                 NaN          NaN   \n",
       "other                                            362096          NaN   \n",
       "poi                                               False        False   \n",
       "restricted_stock                                    NaN          NaN   \n",
       "restricted_stock_deferred                           NaN          NaN   \n",
       "salary                                              NaN          NaN   \n",
       "shared_receipt_with_poi                             NaN          NaN   \n",
       "to_messages                                         NaN          NaN   \n",
       "total_payments                                   362096          NaN   \n",
       "total_stock_value                                   NaN       139130   \n",
       "\n",
       "                          WHALEY DAVID A      TOTAL          LAY KENNETH L  \\\n",
       "bonus                                NaN   97343619                7000000   \n",
       "deferral_payments                    NaN   32083396                 202911   \n",
       "deferred_income                      NaN  -27992891                -300000   \n",
       "director_fees                        NaN    1398517                    NaN   \n",
       "email_address                        NaN        NaN  kenneth.lay@enron.com   \n",
       "exercised_stock_options            98718  311764000               34348384   \n",
       "expenses                             NaN    5235198                  99832   \n",
       "from_messages                        NaN        NaN                     36   \n",
       "from_poi_to_this_person              NaN        NaN                    123   \n",
       "from_this_person_to_poi              NaN        NaN                     16   \n",
       "loan_advances                        NaN   83925000               81525000   \n",
       "long_term_incentive                  NaN   48521928                3600000   \n",
       "other                                NaN   42667589               10359729   \n",
       "poi                                False      False                   True   \n",
       "restricted_stock                     NaN  130322299               14761694   \n",
       "restricted_stock_deferred            NaN   -7576788                    NaN   \n",
       "salary                               NaN   26704229                1072321   \n",
       "shared_receipt_with_poi              NaN        NaN                   2411   \n",
       "to_messages                          NaN        NaN                   4273   \n",
       "total_payments                       NaN  309886585              103559793   \n",
       "total_stock_value                  98718  434509511               49110078   \n",
       "\n",
       "                                   LAVORATO JOHN J  \n",
       "bonus                                      8000000  \n",
       "deferral_payments                              NaN  \n",
       "deferred_income                                NaN  \n",
       "director_fees                                  NaN  \n",
       "email_address              john.lavorato@enron.com  \n",
       "exercised_stock_options                    4158995  \n",
       "expenses                                     49537  \n",
       "from_messages                                 2585  \n",
       "from_poi_to_this_person                        528  \n",
       "from_this_person_to_poi                        411  \n",
       "loan_advances                                  NaN  \n",
       "long_term_incentive                        2035380  \n",
       "other                                         1552  \n",
       "poi                                          False  \n",
       "restricted_stock                           1008149  \n",
       "restricted_stock_deferred                      NaN  \n",
       "salary                                      339288  \n",
       "shared_receipt_with_poi                       3962  \n",
       "to_messages                                   7259  \n",
       "total_payments                            10425757  \n",
       "total_stock_value                          5167144  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['LOCKHART EUGENE E', 'GRAMM WENDY L', \\\n",
    "    'THE TRAVEL AGENCY IN THE PARK', \\\n",
    "    'WROBEL BRUCE', 'WHALEY DAVID A', \\\n",
    "    'TOTAL', 'LAY KENNETH L', 'LAVORATO JOHN J']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-5: How to handle outliers?\n",
    "\n",
    "'TOTAL' seemed an outlier introduced by spreadsheet quirk. It was the sum of all entries from the [pdf financial data](enron61702insiderpay.pdf). It needs to be removed from the dataset.\n",
    "\n",
    "In addition, 'LOCKHART EUGENE E' might need to be removed as well because he does not have any value other than NaN and is labeled as non-POI. \n",
    "\n",
    "Among the outliers and data points with too many missing values, only 'LAY KENNETH L' was labeled as POI and he was chairman of the Enron board of directors. So I think these extreme values for this individual have a meaningful reason, not introduced by typos or technical errors.\n",
    "\n",
    "'LAVORATO JOHN J' is an interesting individual who was recieved the largest bonus and the most frequently communicated with POI via emails, but he is not labeled as POI. So, I expect that this person would be lied near the border line of classification or tend to be mis-classified.\n",
    "\n",
    "I tend to keep the other outliers detected, including 'THE TRAVEL AGENCY IN THE PARK'. According to the footnote from the [pdf financial data](enron61702insiderpay.pdf), the travel agency was coowned by the sister of Enron's former Chairman and I don't have solid reasons to exclude this from the dataset.\n",
    "\n",
    "- List of data points to remove:\n",
    "    \n",
    "    - 'TOTAL'\n",
    "    - 'LOCKHART EUGENE E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### there's an outlier--remove it! \n",
    "data_dict.pop(\"TOTAL\", 0)\n",
    "data_dict.pop(\"LOCKHART EUGENE E\", 0)\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of key was 146 - 1('TOTAL') - 1(all zeros) = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part2. Feature Engineering\n",
    "\n",
    "As part of the project, I should attempt to engineer my own feature that does not come ready-made in the dataset. Before creating new features, I need to explore features. \n",
    "\n",
    "## Taka a look at features\n",
    "\n",
    "### 1. Email features\n",
    "\n",
    "    to_messages, from_poi_to_this_person, from_messages, from_this_person_to_poi, shared_receipt_with_poi\n",
    "\n",
    "\n",
    "Among 6 of email features, I think email_address can be removed to make all numerical features plus I don't think email_address will give any meaningful information in classifying the labels. \n",
    "\n",
    "\n",
    "### 2. Financial features can be grouped into two categories: payments and stock value\n",
    "\n",
    "| categories  | features with positive values                                                                        | features with negative values | summed to         |\n",
    "|-------------|------------------------------------------------------------------------------------------------------|-------------------------------|-------------------|\n",
    "| payments    | salary, bonus, long_term_incentive, deferral_payments, loan_advances, other, expenses, director_fees | deferred_income               | total_payments    |\n",
    "| stock value | exercised_stock_options, restricted_stock                                                            | restricted_stock_deferred     | total_stock_value |\n",
    "\n",
    "'total_payments' and 'total_stock_value' are the summary features of each category. They can either well represent the latent features of the two category or cancel out meaningful patterns of individual features. So, here are some potential ways I can engineer the features.\n",
    "\n",
    "## Braindstorm How to Treat Features\n",
    "\n",
    "### 1. Treate all the numerical features individually\n",
    "    - Feature transformation using PCA (requires feature scaling prior to PCA) then feature selection\n",
    "    - Feature selection directly without any transformation\n",
    "### 2. Treate the numerical features as 3 latent features (payment, stock, and email)\n",
    "    - Feature transformation using PCA separately (each latent feature has a set of PCA feature) then feature selection\n",
    "    - Relativization prior to PCA transformation then feature selection\n",
    "    - Relativization then feature selection\n",
    "Mixing features with absolute values and those with relative values can provide more potential ways in feature engineering, but for now I focus on comparing feature importances or scores of 5 different combinations described above.\n",
    "\n",
    "**Relativization can be achieved two ways:**\n",
    "    1. feature/summed to\n",
    "    2. feature/(summed to - feature with negative values) because feature with negative values canceled out the sum\n",
    "                \n",
    "**For email features, create features relative fraction of messages exchanged with POI among total messages:**\n",
    "     1. (\"from_this_person_to_poi\" + \"from_poi_to_this_person\")/(\"from_messages\" + \"to_messages\")\n",
    "     2. \"from_poi_to_this_person\"/\"to_messages\n",
    "     3. \"from_this_person_to_poi\"/\"from_messages\"\n",
    "\n",
    "# Create new features\n",
    "\n",
    "## Q2-1: what features to create and the rationale behind it\n",
    "I will create 12 new features of the relative values of payment and stock by using relativization method 1. and 3 new features of the fraction of emails exchanged with POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salary',\n",
       " 'to_messages',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'exercised_stock_options',\n",
       " 'bonus',\n",
       " 'restricted_stock',\n",
       " 'shared_receipt_with_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'loan_advances',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'from_this_person_to_poi',\n",
       " 'director_fees',\n",
       " 'deferred_income',\n",
       " 'long_term_incentive',\n",
       " 'from_poi_to_this_person']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to seperate the POI label from feature_list and remove email_address\n",
    "features_list.remove('poi')\n",
    "features_list.remove('email_address')\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = ['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new features of relative values of each payment feature to total_payments\n",
    "payment_features = ['salary', 'bonus', 'long_term_incentive', \\\n",
    "                    'deferral_payments', 'loan_advances', 'other', \\\n",
    "                    'expenses', 'director_fees', 'deferred_income']\n",
    "\n",
    "for feature in payment_features:\n",
    "    new_feature_name = 'rel_' + feature\n",
    "    df_trans[new_feature_name] = (df_trans[feature]/df_trans['total_payments']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new features of relative values of each stock feature to total_stock_value\n",
    "stock_features = ['exercised_stock_options', 'restricted_stock', \\\n",
    "                  'restricted_stock_deferred']\n",
    "\n",
    "for feature in stock_features:\n",
    "    new_feature_name = 'rel_' + feature\n",
    "    df_trans[new_feature_name] = (df_trans[feature]/df_trans['total_stock_value']).replace([np.inf, -np.inf, np.nan], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new features of fraction of emails exchanged with POI\n",
    "df_trans['fraction_poi']=((df_trans['from_this_person_to_poi']+\\\n",
    "                          df_trans['from_poi_to_this_person'])/\\\n",
    "(df_trans['from_messages']+df_trans['to_messages'])).fillna(0)\n",
    "\n",
    "df_trans['fraction_to_poi']=(df_trans['from_this_person_to_poi']/\\\n",
    "df_trans['from_messages']).fillna(0)\n",
    "\n",
    "df_trans['fraction_from_poi']=(df_trans['from_poi_to_this_person']/\\\n",
    "df_trans['to_messages']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>...</th>\n",
       "      <th>rel_other</th>\n",
       "      <th>rel_expenses</th>\n",
       "      <th>rel_director_fees</th>\n",
       "      <th>rel_deferred_income</th>\n",
       "      <th>rel_exercised_stock_options</th>\n",
       "      <th>rel_restricted_stock</th>\n",
       "      <th>rel_restricted_stock_deferred</th>\n",
       "      <th>fraction_poi</th>\n",
       "      <th>fraction_to_poi</th>\n",
       "      <th>fraction_from_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.759974e+05</td>\n",
       "      <td>2.220896e+05</td>\n",
       "      <td>-1.936833e+05</td>\n",
       "      <td>9980.319444</td>\n",
       "      <td>2.075802e+06</td>\n",
       "      <td>35375.340278</td>\n",
       "      <td>363.583333</td>\n",
       "      <td>38.756944</td>\n",
       "      <td>24.625000</td>\n",
       "      <td>5.828125e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108559</td>\n",
       "      <td>0.095527</td>\n",
       "      <td>5.914364</td>\n",
       "      <td>-6.082185</td>\n",
       "      <td>0.498924</td>\n",
       "      <td>0.403771</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.109922</td>\n",
       "      <td>0.022672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.233155e+06</td>\n",
       "      <td>7.541013e+05</td>\n",
       "      <td>6.060111e+05</td>\n",
       "      <td>31300.575144</td>\n",
       "      <td>4.795513e+06</td>\n",
       "      <td>45309.303038</td>\n",
       "      <td>1450.675239</td>\n",
       "      <td>74.276769</td>\n",
       "      <td>79.778266</td>\n",
       "      <td>6.794472e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.240176</td>\n",
       "      <td>58.879276</td>\n",
       "      <td>58.868342</td>\n",
       "      <td>0.396188</td>\n",
       "      <td>0.473146</td>\n",
       "      <td>0.255201</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.185935</td>\n",
       "      <td>0.036417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-3.504386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-701.013514</td>\n",
       "      <td>-0.074502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.493526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.708600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.077054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>20182.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627935</td>\n",
       "      <td>0.284209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>8.535500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.683580e+06</td>\n",
       "      <td>53328.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075646</td>\n",
       "      <td>0.055635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850136</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043337</td>\n",
       "      <td>0.198827</td>\n",
       "      <td>0.029918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>6.426990e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>137864.000000</td>\n",
       "      <td>3.434838e+07</td>\n",
       "      <td>228763.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>8.152500e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>701.013514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.493526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  1.440000e+02       1.440000e+02     1.440000e+02     144.000000   \n",
       "mean   6.759974e+05       2.220896e+05    -1.936833e+05    9980.319444   \n",
       "std    1.233155e+06       7.541013e+05     6.060111e+05   31300.575144   \n",
       "min    0.000000e+00      -1.025000e+05    -3.504386e+06       0.000000   \n",
       "25%    0.000000e+00       0.000000e+00    -3.708600e+04       0.000000   \n",
       "50%    3.000000e+05       0.000000e+00     0.000000e+00       0.000000   \n",
       "75%    8.000000e+05       8.535500e+03     0.000000e+00       0.000000   \n",
       "max    8.000000e+06       6.426990e+06     0.000000e+00  137864.000000   \n",
       "\n",
       "       exercised_stock_options       expenses  from_messages  \\\n",
       "count             1.440000e+02     144.000000     144.000000   \n",
       "mean              2.075802e+06   35375.340278     363.583333   \n",
       "std               4.795513e+06   45309.303038    1450.675239   \n",
       "min               0.000000e+00       0.000000       0.000000   \n",
       "25%               0.000000e+00       0.000000       0.000000   \n",
       "50%               6.082935e+05   20182.000000      17.500000   \n",
       "75%               1.683580e+06   53328.250000      53.000000   \n",
       "max               3.434838e+07  228763.000000   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "count               144.000000               144.000000   1.440000e+02   \n",
       "mean                 38.756944                24.625000   5.828125e+05   \n",
       "std                  74.276769                79.778266   6.794472e+06   \n",
       "min                   0.000000                 0.000000   0.000000e+00   \n",
       "25%                   0.000000                 0.000000   0.000000e+00   \n",
       "50%                   4.000000                 0.000000   0.000000e+00   \n",
       "75%                  41.250000                14.000000   0.000000e+00   \n",
       "max                 528.000000               609.000000   8.152500e+07   \n",
       "\n",
       "             ...           rel_other  rel_expenses  rel_director_fees  \\\n",
       "count        ...          144.000000    144.000000         144.000000   \n",
       "mean         ...            0.108559      0.095527           5.914364   \n",
       "std          ...            0.221239      0.240176          58.879276   \n",
       "min          ...            0.000000      0.000000           0.000000   \n",
       "25%          ...            0.000000      0.000000           0.000000   \n",
       "50%          ...            0.000720      0.015768           0.000000   \n",
       "75%          ...            0.075646      0.055635           0.000000   \n",
       "max          ...            1.000000      1.000000         701.013514   \n",
       "\n",
       "       rel_deferred_income  rel_exercised_stock_options  rel_restricted_stock  \\\n",
       "count           144.000000                   144.000000            144.000000   \n",
       "mean             -6.082185                     0.498924              0.403771   \n",
       "std              58.868342                     0.396188              0.473146   \n",
       "min            -701.013514                    -0.074502              0.000000   \n",
       "25%              -0.077054                     0.000000              0.000000   \n",
       "50%               0.000000                     0.627935              0.284209   \n",
       "75%               0.000000                     0.850136              0.650782   \n",
       "max               0.000000                     1.000000              3.493526   \n",
       "\n",
       "       rel_restricted_stock_deferred  fraction_poi  fraction_to_poi  \\\n",
       "count                     144.000000    144.000000       144.000000   \n",
       "mean                       -0.049046      0.028493         0.109922   \n",
       "std                         0.255201      0.042827         0.185935   \n",
       "min                        -2.493526      0.000000         0.000000   \n",
       "25%                         0.000000      0.000000         0.000000   \n",
       "50%                         0.000000      0.008772         0.000000   \n",
       "75%                         0.000000      0.043337         0.198827   \n",
       "max                         0.000000      0.224352         1.000000   \n",
       "\n",
       "       fraction_from_poi  \n",
       "count         144.000000  \n",
       "mean            0.022672  \n",
       "std             0.036417  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.004952  \n",
       "75%             0.029918  \n",
       "max             0.217341  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0L"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check any numpy NaN\n",
    "df_trans.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'salary', u'to_messages', u'deferral_payments', u'total_payments',\n",
      "       u'exercised_stock_options', u'bonus', u'restricted_stock',\n",
      "       u'shared_receipt_with_poi', u'restricted_stock_deferred',\n",
      "       u'total_stock_value', u'expenses', u'loan_advances', u'from_messages',\n",
      "       u'other', u'from_this_person_to_poi', u'director_fees',\n",
      "       u'deferred_income', u'long_term_incentive', u'from_poi_to_this_person'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create subset of dataframe including only original features\n",
    "original_df = df_trans[features_list]\n",
    "original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python dictionary or pandans dataframe can’t be read directly into an sklearn classification or regression algorithm; instead, it needs a **numpy array** or a list of lists (each element of the list (itself a list) is a data point, and the elements of the smaller list are the features of that point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  201955     2902  2869717 ..., -3081055   304805       47]\n",
      " [       0        0   178980 ...,        0        0        0]\n",
      " [     477      566        0 ...,    -5104        0       39]\n",
      " ..., \n",
      " [       0        0        0 ...,        0        0        0]\n",
      " [  158403        0        0 ...,        0        0        0]\n",
      " [       0        0        0 ...,        0        0        0]]\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe to numpy array\n",
    "orginal_nparry = original_df.as_matrix()\n",
    "print orginal_nparry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_nparray = df_trans['poi'].as_matrix()\n",
    "label_nparray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "## Q2-2: do I have to do any scaling? why or why not?\n",
    "Yes. I will use **MinMaxScaler** to adjust financial (in $) and email (count) features to be equally weighted and ranged between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\4jude\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.81735475e-01,   1.91563800e-01,   4.55198951e-01,\n",
       "         4.33029255e-02,   5.03529074e-02,   5.21875000e-01,\n",
       "         1.57231836e-01,   2.54845137e-01,   9.63456735e-02,\n",
       "         3.60830823e-02,   6.06216914e-02,   0.00000000e+00,\n",
       "         1.52770045e-01,   1.46721985e-05,   1.06732348e-01,\n",
       "         0.00000000e+00,   1.20800334e-01,   5.92379574e-02,\n",
       "         8.90151515e-02])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "original_scaled = scaler.fit_transform(orginal_nparry)\n",
    "original_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144L, 19L)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_scaled.shape # returns length of array and length of item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Q2-3: what selection process to use?\n",
    "\n",
    "The goal of feature selection is to select best 7 or less features. The number 7 threshold came from the curve of dimensionality, where you may need exponentially more data points as you add more features, that is, 2^(n_featuers) = # of data points. I have 144 data points. 2^7 = 128, so 7 is the max feature number. Thus, I use **SelectKBest** process to pick 7 features.\n",
    "\n",
    "## Q2-4: what feature scores to compare and reasons for the choice of parameter values\n",
    "\n",
    "I choose **f_classif** scoring function over variances, chi2, and mutual_info_classif. \n",
    "\n",
    "- Variance can be useful for unsupervised classification. Since I have already labels, utilizing labels for scoring could be better than soley reling on x-variables. \n",
    "\n",
    "- The chi-square distribution arises in tests of hypotheses concerning the independence of two random variables and concerning whether a discrete random variable follows a specified distribution. The F-distribution arises in tests of hypotheses concerning whether or not two population variances are equal and concerning whether or not three or more population means are equal. In other words, chi-square is most appropriate for categorical data, whereas f-value can be used for continuous data.\n",
    "\n",
    "- The mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold\n",
    "https://discussions.udacity.com/t/f-classif-versus-chi2/245226\n",
    "https://stats.libretexts.org/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/11%3A_Chi-Square_Tests_and_F-Tests\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features with F-value & p-value:\n",
      "1 ('exercised_stock_options', 25.097541528735491, 1.5945438463623382e-06)\n",
      "2 ('total_stock_value', 24.467654047526391, 2.1058066490127594e-06)\n",
      "3 ('bonus', 21.060001707536578, 9.7024743412322453e-06)\n",
      "4 ('salary', 18.575703268041778, 3.0337961075305315e-05)\n",
      "5 ('deferred_income', 11.595547659732164, 0.00085980314391924004)\n",
      "6 ('long_term_incentive', 10.072454529369448, 0.0018454351466116368)\n",
      "7 ('restricted_stock', 9.3467007910514379, 0.0026699611393240469)\n",
      "8 ('total_payments', 8.8667215371077805, 0.0034159213705928374)\n",
      "9 ('shared_receipt_with_poi', 8.7464855321290802, 0.0036344020243633686)\n",
      "10 ('loan_advances', 7.2427303965360172, 0.0079738162605691599)\n",
      "11 ('expenses', 6.234201140506757, 0.013673150875383932)\n",
      "12 ('from_poi_to_this_person', 5.3449415231473347, 0.022220727960811395)\n",
      "13 ('other', 4.2049708583014187, 0.042144700903259204)\n",
      "14 ('from_this_person_to_poi', 2.4265081272428799, 0.12152433983710857)\n",
      "15 ('director_fees', 2.1076559432760891, 0.14876949527311398)\n",
      "16 ('to_messages', 1.6988243485808538, 0.19455111487450777)\n",
      "17 ('deferral_payments', 0.21705893033950563, 0.64200389403828306)\n",
      "18 ('from_messages', 0.16416449823428589, 0.68596070789958996)\n",
      "19 ('restricted_stock_deferred', 0.064984311723709831, 0.7991535567029634)\n"
     ]
    }
   ],
   "source": [
    "# select 7 features that have highest ANOVA F-value with the factor by poi label\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "selector = SelectKBest(k=7)\n",
    "original_7selected = selector.fit_transform(original_scaled, label_nparray)\n",
    "scores = zip(features_list, selector.scores_, selector.pvalues_)\n",
    "sorted_scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "print\"features with F-value & p-value:\"\n",
    "\n",
    "n=0\n",
    "while (n < len(sorted_scores)):\n",
    "    print n+1, sorted_scores[n]\n",
    "    n +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144L, 7L)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_7selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exercised_stock_options', 'total_stock_value', 'bonus', 'salary', 'deferred_income', 'long_term_incentive', 'restricted_stock']\n"
     ]
    }
   ],
   "source": [
    "optimized_features_list = list(map(lambda x: x[0], sorted_scores))[0:7]\n",
    "print(optimized_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part3. Algorithm Selection\n",
    "\n",
    "# Validation Strategy\n",
    "\n",
    "## Q3-1: what is validation?\n",
    "Validation is an important process to asset the performance of a machine-learning algorithm. \n",
    "\n",
    "## Q3-2: what is a classic mistake you can make if you do it wrong? \n",
    "A classic mistake for my analysis is over-fitting. Learning the parameters of a prediction function and testing it on the same data is a methodological mistake, leading almost a perfect score, but it would fail to predict on unseen data. \n",
    "\n",
    "## Q3-3: how did you validate your analysis?  \n",
    "I think a proper validation method for the dataset with imbalanced classes is using cross validation iterators with stratification based on class labels, such as **StratifiedKFold** and **StratifiedShuffleSplit**. This would ensure that relative class frequencies is approximately preserved in each train and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96L, 7L) (96L,)\n",
      "(48L, 7L) (48L,)\n"
     ]
    }
   ],
   "source": [
    "# generate iter 3 train-test pairs\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=44)\n",
    "\n",
    "for train_index, test_index in skf.split(original_7selected, label_nparray):\n",
    "   #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = original_7selected[train_index], original_7selected[test_index]\n",
    "   y_train, y_test = label_nparray[train_index], label_nparray[test_index]\n",
    "\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96L, 7L) (96L,)\n",
      "(48L, 7L) (48L,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.33, random_state=44)\n",
    "\n",
    "for train_index, test_index in sss.split(original_7selected, label_nparray):\n",
    "   #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = original_7selected[train_index], original_7selected[test_index]\n",
    "   y_train, y_test = label_nparray[train_index], label_nparray[test_index]\n",
    "\n",
    "print X_train.shape, y_train.shape\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Selection\n",
    "\n",
    "## Q3-4: what algorithms to begin? \n",
    "Linear SVC\n",
    "KNeighbors Classifier\n",
    "SVC ensemble classifier\n",
    "\n",
    "## 1. SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888895"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = svm.LinearSVC()\n",
    "\n",
    "scores = cross_val_score(clf, original_7selected, label_nparray, cv=skf)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = svm.SVC(kernel='rbf', probability=True)\n",
    "\n",
    "scores = cross_val_score(clf2, original_7selected, label_nparray, cv=skf)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNeighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88194444444444453"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(neigh, original_7selected, label_nparray, cv=skf)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensemble Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('knn', neigh), ('svc', clf2)], voting='soft')\n",
    "\n",
    "scores = cross_val_score(eclf, original_7selected, label_nparray, cv=skf)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3-5: how did model performance differ between algorithms?\n",
    "Based on accuracy, they are not very different in performance.\n",
    "\n",
    "# Evaluation Metrics Usage\n",
    "\n",
    "## Q3-6:give at least 2 evaluation metrics and your average performance for each of them.\n",
    "\n",
    "- accuracy: correct label (predicted label == true label)/total testing data points\n",
    "- precision: true POI/(true POI + false non-POI)\n",
    "- recall: true POI/(true POI + false POI)\n",
    "- average_precision: the area under the precision-recall curve\n",
    "- f1: 2 * (precision * recall) / (precision + recall)\n",
    "- f1_weighted: Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.888888888889\n",
      "precision : 0.555555555556\n",
      "recall : 0.166666666667\n",
      "average_precision : 0.471586263306\n",
      "f1 : 0.243386243386\n",
      "f1_weighted : 0.852830616081\n"
     ]
    }
   ],
   "source": [
    "scorer = [\"accuracy\", \"precision\", \"recall\", \"average_precision\", \"f1\", \"f1_weighted\"]\n",
    "for score in scorer:\n",
    "    m_score = cross_val_score(clf1, original_7selected, label_nparray, cv=skf, \\\n",
    "                        scoring=score).mean()\n",
    "    print score, ':', m_score\n",
    "\n",
    "#https://stackoverflow.com/questions/35876508/evaluate-multiple-scores-on-sklearn-cross-val-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.872916666667\n",
      "precision : 0.35\n",
      "recall : 0.116666666667\n",
      "average_precision : 0.331737450391\n",
      "f1 : 0.16380952381\n",
      "f1_weighted : 0.835134545196\n"
     ]
    }
   ],
   "source": [
    "for score in scorer:\n",
    "    m_score = cross_val_score(clf1, original_7selected, label_nparray, cv=sss, \\\n",
    "                        scoring=score).mean()\n",
    "    print score, ':', m_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3-7: Explain an interpretation of the metrics that says something human-understandable about the algorithm’s performance.\n",
    "\n",
    "Overall performance of Linear SVC to identify POI labels was poor. The accuracy and f1_weighted scores are based on both true POI and true non-POI labels and showed relatively high performance, where the scores were highly weighted by non-POI label with 87.5% of class size. If all people in the testing set (which was splited by stratifying) are predicted to be non-POI, the accuracy will be as high as 87.5% regardless any feature values of individuals. Thus, the accuracies around 88% are meaningless evaluation and indicate that the classifier is not a very insightful strategy in this case. \n",
    "\n",
    "The precision score showed that 1 out of 3 predicted as POI was truely POI, while the mojority was false positive. This result will be costly in practice because we need to investigate a lot of non-POIs to catch small number of POI. This also increases a chance of that inocent people get legal punishment. \n",
    "\n",
    "The recall score showed that only 1 out of 10 true POIs was identified as POI, while 90% of true POIs were not identified as POI. If we rely on this classifier, we only can catch 10% of the bad guys and let 90% of the bad guys go. \n",
    "\n",
    "f1 is about middle point of precision and recall scores, showing that overall performance of this classifier is very poor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finacial_feature_list = ['salary', 'deferral_payments', 'total_payments', \n",
    "                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "               'deferred_income', 'total_stock_value', 'expenses',\n",
    "               'exercised_stock_options', 'other', 'long_term_incentive',\n",
    "               'restricted_stock', 'director_fees'] \n",
    "\n",
    "# numeric feataure list which excludes email adress\n",
    "email_feature_list = ['to_messages', 'from_poi_to_this_person', 'from_messages',\n",
    "                     'from_this_person_to_poi', 'shared_receipt_with_poi', \n",
    "                      \"fraction_from_poi\", \"fraction_to_poi\"]\n",
    "label = ['poi']\n",
    "\n",
    "total_feature_list = label + finacial_feature_list + email_feature_list\n",
    "\n",
    "print total_feature_list\n",
    "print len(total_feature_list)\n",
    "print len(finacial_feature_list)\n",
    "print len(email_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total 23 key-value pairs per name minus 1 key-value pair(email_address). So now we have 14 finacial features, 7 email features, and 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all numeric features and convert dictionary to numpy array of features\n",
    "data_nparray = featureFormat(data_dict, total_feature_list)\n",
    "poi, total_features = targetFeatureSplit(data_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many data points (people) are in the dataset?\n",
    "# number of keys\n",
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_nparray[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach1\n",
    "Feature selection directly without any transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call for salary\n",
    "data_nparray[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_nparray_wNaN[:, 1]\n",
    "data_nparray_wNaN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why there are negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of deferral_payments\n",
    "min(data_nparray[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of deferrd_income\n",
    "min(data_nparray[:, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min of total_stock_value\n",
    "min(data_nparray[:, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the financial data have negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "rescaled_data_nparray_imp = scaler.fit_transform(data_nparray_wNaN_imp)\n",
    "rescaled_data_nparray_imp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why median value is not around 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_mean = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data_nparray_wNaN_imp_mean = imp_mean.fit_transform(data_nparray_wNaN)\n",
    "print data_nparray_wNaN_imp_mean[0] \n",
    "print \n",
    "rescaled_data_nparray_imp_mean = scaler.fit_transform(data_nparray_wNaN_imp_mean)\n",
    "print rescaled_data_nparray_imp_mean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why mean value is not around 0.5. I think it is because the mean value calculated without the number of the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stand = StandardScaler()\n",
    "stand_data_nparray_imp = stand.fit_transform(data_nparray_wNaN_imp)\n",
    "stand_data_nparray_imp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_array = rescaled_data_nparray_imp[:, 0]\n",
    "rescaled_total_data_nparray_imp = rescaled_data_nparray_imp[:, 1:]\n",
    "rescaled_financial_data_nparray_imp = rescaled_data_nparray_imp[:, 1:15]\n",
    "rescaled_email_data_nparray_imp = rescaled_data_nparray_imp[:, 15:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# important financial features\n",
    "\n",
    "clf.fit(rescaled_financial_data_nparray_imp, poi_array)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Financial Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{}: no.{}, {} ({})\".format(i+1,indices[i],\n",
    "                                      finacial_feature_list[indices[i]], \n",
    "                                      importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# important email features\n",
    "\n",
    "clf.fit(rescaled_email_data_nparray_imp, poi_array)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Email Feature Ranking: '\n",
    "for i in range(5):\n",
    "    print \"{}: no.{}, {} ({})\".format(i+1,indices[i],\n",
    "                                      email_feature_list[indices[i]], \n",
    "                                      importances[indices[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(rescaled_total_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_ # % of variance explained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# financial featrues\n",
    "pca.fit(rescaled_financial_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# email featrues\n",
    "pca.fit(rescaled_email_data_nparray_imp)\n",
    "\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
